package nl.uu.cs.ape.sat.models;

import java.util.ArrayList;
import java.util.Collection;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import nl.uu.cs.ape.sat.automaton.TypeAutomaton;
import nl.uu.cs.ape.sat.automaton.Block;
import nl.uu.cs.ape.sat.automaton.State;
import nl.uu.cs.ape.sat.models.enums.NodeType;
import nl.uu.cs.ape.sat.models.enums.WorkflowElement;
import nl.uu.cs.ape.sat.models.logic.constructs.Predicate;
import nl.uu.cs.ape.sat.utils.APEConfig;

/**
 * The {@code AllTypes} class represent the set of all data dimensions (e.g. types,formats, etc.) that
 * can be used in our program.
 * 
 * @author Vedran Kasalica
 *
 */
public class AllTypes extends HashMap<String, Type>{


	/**
	 * Set of all the type IDs of the annotated type in the domain, ie. types that
	 * can be used or generated by the annotated tools.
	 */
	private Set<String> annotatedTypes;
	/** {@link Type} object representing the "empty type". */
	private Type emptyType;
	/** List of nodes in the ontology that correspond to the roots of disjoint sub-taxonomies, where each represents a data dimension (e.g. data type, data format, etc.).*/
	private List<String> dataTaxonomyDimensions;
	/** Root of the data taxonomy. */
	private String dataTaxonomyRoot;

	public AllTypes() {
		super();
		this.annotatedTypes = new HashSet<String>();
		dataTaxonomyDimensions = APEConfig.getConfig().getData_taxonomy_subroots();
		dataTaxonomyRoot = APEConfig.getConfig().getData_taxonomy_root();
		emptyType = new Type("empty", "empty", dataTaxonomyRoot, NodeType.EMPTY);
		this.put(emptyType);
	}

	/**
	 * Returns the set of {@link Type}s that are currently defined.  
	 * @return {@link Collection} of {@link Type}s
	 */
	public Collection<Type> getTypes() {
		return this.values();
	}

	/**
	 * Adds the specified element to this set if it is not already present (optional
	 * operation) and returns it. More formally, adds the specified element e to
	 * this set if the set contains no element e2 such that (e==null ? e2==null :
	 * e.equals(e2)). If this set already contains the element, the call leaves the
	 * set unchanged and returns the existing element. In combination with the
	 * restriction on constructors, this ensures that sets never contain duplicate
	 * elements.
	 * 
	 * @param type - the element that needs to be added
	 * @return The same element if it's a new one or the existing element if this
	 *         set contains the specified element.
	 */
	private Type put(Type type) {
		Type tmpType;
		if ((tmpType = this.get(type.getPredicateID())) != null) {
			return tmpType;
		} else {
			super.put(type.getPredicateID(), type);
			return type;
		}
	}
	
	/**
	 * The method is used to check weather the type with typeID was already
	 * introduced earlier on in {@code allTypes}. In case it was, it returns the item,
	 * otherwise the new element is generated and returned. <br>
	 * <br>
	 * In case of generating a new Type, the object is added to the set of all the
	 * DataInstance and added as a subType to the parent Type.
	 * 
	 * @param typeName  - Type name
	 * @param typeID    - Unique Type identifier
	 * @param rootType  - Determines whether the Type is a simple/leaf type
	 * @param nodeType  - {@link NodeType} object describing the type w.r.t. the
	 *                  Type Taxonomy.
	 * @param superType - The Parent (abstract) Type of the current Type
	 * @return The Type object.
	 */
	public Type addType(String typeName, String typeID, String rootType, NodeType nodeType,
			Type superType) {

		Type tmpType;
		if ((tmpType = this.get(typeID)) == null) {
			tmpType = new Type(typeName, typeID, rootType, nodeType);
			this.put(tmpType);

		}
		/*
		 * Adding class as a subtype to the superclass, even if currType was already
		 * introduced (extending taxonomy tree)
		 */
		if (superType != null) {
			superType.addSubType(typeID);
		}

		return tmpType;

	}

	/**
	 * Returns the type to which the specified key is mapped to, or {@code null} if
	 * the typeID has no mappings.
	 * 
	 * @param typeID - the key whose associated value is to be returned
	 * @return {@link Type} to which the specified key is mapped to, or {@code null}
	 *         if the typeID has no mappings
	 */
	public Type get(String typeID) {
		return super.get(typeID);
	}

	/**
	 * Returns the root type of the taxonomy.
	 * 
	 * @return The root type.
	 */
	public Type getRootType() {
		return this.get(dataTaxonomyRoot);
	}
	
	/**
	 * Returns the ID of the root type of the taxonomy.
	 * 
	 * @return The root type ID.
	 */
	public String getRootID() {
		return dataTaxonomyRoot;
	}

	/**
	 * Returns the type representation of the empty type.
	 * 
	 * @return The empty type.
	 */
	public Type getEmptyType() {
		return this.emptyType;
	}

	/**
	 * Returns true if this set contains the specified type element. More formally,
	 * returns true if and only if this set contains an element e such that (o==null
	 * ? e==null : o.equals(e)).
	 * 
	 * @param type - type that is searched for
	 * @return {@code true} if the type exists in the set.
	 */
	public boolean existsType(Type type) {
		return this.containsKey(type.getPredicateID());
	}

	/**
	 * Returns number of types currently defined.
	 * @return Number of types.
	 */
	public int size() {
		return super.size();
	}

	/**
	 * Returns a list of pairs of simple types. Note that the abstract types are not
	 * returned, only the unique pairs of types that are representing leaf types in
	 * the taxonomy tree.
	 * 
	 * @return list of pairs of types
	 */
	private List<Pair> getTypePairs() {
		List<Pair> pairs = new ArrayList<Pair>();

		List<Type> iterator = new ArrayList<Type>();
		for (Type type : this.values()) {
			if (type.isSimpleType() || type.isEmptyType()) {
				iterator.add(type);
			}
		}

		for (int i = 0; i < iterator.size() - 1; i++) {
			for (int j = i + 1; j < iterator.size(); j++) {

				pairs.add(new Pair(iterator.get(i), iterator.get(j)));
			}
		}

		return pairs;
	}

	/**
	 * Returns a list of pairs of simple types, pairing the types based on the
	 * taxonomy subtree they belong to. Note that the abstract types are not
	 * returned, only the unique pairs of types that are representing leaf types in
	 * the same taxonomy sub tree, including the empty type (e.g. DataTypeTaxonomy
	 * or DataFormatTaxonomt tree)
	 * 
	 * @return list of pairs of types
	 */
	private List<Pair> getTypePairsForEachSubTaxonomy() {
		List<Pair> pairs = new ArrayList<Pair>();

		/*
		 * Create a list for each subtree of the Data Taxonomy (e.g. TypeSubTaxonomy,
		 * FormatSubTaxonomy). Each of these lists represents a class of mutually
		 * exclusive types.
		 */
		Map<String, List<Type>> subTreesMap = new HashMap<String, List<Type>>();
		// Add general data taxonomy root to the list
		subTreesMap.put(dataTaxonomyRoot, new ArrayList<Type>());
		// Add each of the subtree roots (type and format taxonomy) to the list
		for (String subRoot : dataTaxonomyDimensions) {
			subTreesMap.put(subRoot, new ArrayList<Type>());
		}

		/**
		 * Allocate each simple type to the corresponding subtree, according to the
		 * field Type.rootNode
		 */
		for (Type type : this.values()) {
			if (type.isSimpleType()) {
				// If the root type for the curr type exists in our list, add the type to it
				if (subTreesMap.get(type.getRootNode()) != null) {
					subTreesMap.get(type.getRootNode()).add(type);
				}
			} else if (type.isEmptyType()) {
				/*
				 * Add empty type to each mutual exclusive class
				 */
				for (List<Type> currSubTree : subTreesMap.values()) {
					currSubTree.add(type);
				}
			}
		}

		for (List<Type> iterator : subTreesMap.values()) {
			for (int i = 0; i < iterator.size() - 1; i++) {
				for (int j = i + 1; j < iterator.size(); j++) {
					pairs.add(new Pair(iterator.get(i), iterator.get(j)));
				}
			}
		}

		return pairs;
	}

	/**
	 * Returns a list of final types. Note that the abstract types are not returned,
	 * only the types that are representing leaf types in the taxonomy tree.
	 * 
	 * @return list of types
	 */
	private List<Type> getAllNonEmptyTypes() {

		List<Type> allNonEmptyTypes = new ArrayList<Type>();
		for (Type type : this.values()) {
			if (!(type.isEmptyType() || type.isRootType())) {
//				System.out.println("Type: " + type.getPredicate() + ", is root:" + type.isRootType() + ", is empty:" + type.isEmptyType());
				allNonEmptyTypes.add(type);
			}
		}

		return allNonEmptyTypes;
	}

	/**
	 * Return {@code true} if the type is annotated, i.e. used as I/O by the annotated tools.
	 * 
	 * @param typeID - ID of the type that is evaluated.
	 * @return {@code true} if the type is annotated, {@code false} otherwise.
	 */
	public boolean getIsAnnotatedType(String typeID) {
		return annotatedTypes.contains(typeID);
	}

	/**
	 * Adds the type ID to the set of annotated type (used as I/O by the annotated tools).
	 * 
	 * @param typeID - ID of the type that is annotated.
	 */
	public void addAnnotatedType(String typeID) {
		annotatedTypes.add(typeID);
	}
	
	/**
	 * Return the list of dimensions that represent the data. Each dimension represents a node in the data taxonomy and the root for the corresponding sub-taxonomy.
	 * @return List of abstract types that represent dimensions.
	 */
	public List<String> getDataTaxonomyDimensions(){
		return dataTaxonomyDimensions;
	}

	/**
	 * Generating the mutual exclusion for each pair of tools from @modules
	 * (excluding abstract modules from the taxonomy) in each state
	 * of @moduleAutomaton.
	 * 
	 * @param modules
	 * @param typeAutomaton
	 * @param mappings
	 * @return String representation of constraints
	 */
	public String typeMutualExclusion(TypeAutomaton typeAutomaton, AtomMapping mappings) {

		StringBuilder constraints = new StringBuilder();
		Predicate firstPair, secondPair;
		for (Pair pair : getTypePairsForEachSubTaxonomy()) {
			firstPair = pair.getFirst();
			secondPair = pair.getSecond();
			// mutual exclusion of types in all the states (those that represent general memory)
			for (Block typeBlock : typeAutomaton.getMemoryTypesBlocks()) {
				for (State typeState : typeBlock.getStates()) {
					constraints = constraints.append("-").append(mappings.add(firstPair, typeState, WorkflowElement.MEMORY_TYPE))
							.append(" ");
					constraints = constraints.append("-").append(mappings.add(secondPair, typeState, WorkflowElement.MEMORY_TYPE))
							.append(" ").append("0\n");
				}
			}
			// mutual exclusion of types in all the states (those that represent used instances)
			for (Block typeBlock : typeAutomaton.getUsedTypesBlocks()) {
				for (State typeState : typeBlock.getStates()) {
					constraints = constraints.append("-").append(mappings.add(firstPair, typeState, WorkflowElement.USED_TYPE))
							.append(" ");
					constraints = constraints.append("-").append(mappings.add(secondPair, typeState, WorkflowElement.USED_TYPE))
							.append(" ").append("0\n");
				}
			}
		}
		return constraints.toString();
	}
	
	/**
	 * Generating the mandatory usage constraints of root type @rootType in each
	 * state of @moduleAutomaton.
	 * 
	 * @param rootTypeID      - represent the ID of the root type in the type
	 *                        taxonomy
	 * @param moduleAutomaton - type automaton
	 * @return String representation of constraints
	 */
	public String typeMandatoryUsage(Type type, TypeAutomaton typeAutomaton, AtomMapping mappings) {
		StringBuilder constraints = new StringBuilder();
		// enforcement of types in in all the states (those that represent general
		// memory and used data instances)
		for (Block typeBlock : typeAutomaton.getMemoryTypesBlocks()) {
			for (State typeState : typeBlock.getStates()) {
				constraints = constraints.append(mappings.add(type, typeState, WorkflowElement.MEMORY_TYPE))
						.append(" 0\n");
			}
		}
		for (Block typeBlock : typeAutomaton.getUsedTypesBlocks()) {
			for (State typeState : typeBlock.getStates()) {
				constraints = constraints.append(mappings.add(type, typeState, WorkflowElement.USED_TYPE))
						.append(" 0\n");
			}
		}

		return constraints.toString();
	}

	/**
	 * Generating the mandatory usage of a subtypes in case of the parent type being
	 * used, with respect to the Type Taxonomy. The rule starts from the @rootType
	 * and it's valid in each state of @typeAutomaton. @emptyType denotes the type
	 * that is being used if the state has no type.
	 * 
	 * @param rootTypeID    - represent the ID of the root type in the type taxonomy
	 * @param emptyTypeID   - represent the ID of the empty type in the type
	 *                      taxonomy
	 * @param typeAutomaton - type automaton
	 * @param mappings      - mapping function
	 * @return String representation of constraints enforcing taxonomy
	 *         classifications
	 */
	public String typeEnforceTaxonomyStructure(String rootTypeID, TypeAutomaton typeAutomaton, AtomMapping mappings) {

		StringBuilder constraints = new StringBuilder();
		// taxonomy enforcement of types in in all the states (those that represent
		// general memory and used data instances)
		for (Block memTypeBlock : typeAutomaton.getMemoryTypesBlocks()) {
			for (State memTypeState : memTypeBlock.getStates()) {
				constraints = constraints
						.append(typeEnforceTaxonomyStructureForState(rootTypeID, mappings, memTypeState, WorkflowElement.MEMORY_TYPE));
			}
		}
		for (Block usedTypeBlock : typeAutomaton.getUsedTypesBlocks()) {
			for (State usedTypeState : usedTypeBlock.getStates()) {
				constraints = constraints.append(typeEnforceTaxonomyStructureForState(rootTypeID, mappings, usedTypeState, WorkflowElement.USED_TYPE));
			}
		}
		return constraints.toString();
	}

	/**
	 * Supporting recursive method for typeEnforceTaxonomyStructure.
	 * @param typeElement 
	 */
	private String typeEnforceTaxonomyStructureForState(String rootTypeID,
			AtomMapping mappings, State typeState, WorkflowElement typeElement) {

		Type currType = this.get(rootTypeID);
		String superType_State = mappings.add(currType, typeState, typeElement).toString();

		StringBuilder constraints = new StringBuilder();
		StringBuilder currConstraint = new StringBuilder("-").append(superType_State).append(" ");

		List<String> subTypes_States = new ArrayList<String>();
		if (!(currType.getSubTypes() == null || currType.getSubTypes().isEmpty())) {
			/*
			 * Ensuring the TOP-DOWN taxonomy tree dependency
			 */
			for (String subTypeeID : currType.getSubTypes()) {
				Type subType = this.get(subTypeeID);

				String subType_State = mappings.add(subType, typeState, typeElement).toString();
				currConstraint = currConstraint.append(subType_State).append(" ");
				subTypes_States.add(subType_State);

				constraints = constraints.append(typeEnforceTaxonomyStructureForState(subTypeeID, mappings, typeState, typeElement));
			}
			currConstraint = currConstraint.append("0\n");
			/*
			 * Ensuring the BOTTOM-UP taxonomy tree dependency
			 */
			for (String subType_State : subTypes_States) {
				currConstraint = currConstraint.append("-").append(subType_State).append(" ").append(superType_State)
						.append(" 0\n");
			}
			return currConstraint.append(constraints).toString();
		} else {
			return "";
		}
	}

	/**
	 * Encoding the initial workflow input.
	 * 
	 * @param program_inputs - input types for the program
	 * @param typeAutomaton
	 * @param solutionLength
	 * @param emptyType
	 * @param mappings
	 * @param allTypes
	 * @return String representation of the initial input encoding.
	 */
	public String encodeInputData(List<DataInstance> program_inputs, TypeAutomaton typeAutomaton, AtomMapping mappings) {
		StringBuilder encoding = new StringBuilder();

		List<State> workfloInputStates = typeAutomaton.getMemoryTypesBlock(0).getStates();
		for (int i = 0; i < workfloInputStates.size(); i++) {
			if (i < program_inputs.size()) {
				List<Type> currTypes = program_inputs.get(i).getTypes();
				for (Type currType : currTypes) {
					if (get(currType.getPredicateID()) == null) {
						System.err.println(
								"Program input '" + currType.getPredicateID() + "' was not defined in the taxonomy.");
						return null;
					}
					
					encoding = encoding.append(mappings.add(currType, workfloInputStates.get(i), WorkflowElement.MEMORY_TYPE))
							.append(" 0\n");
					this.addAnnotatedType(currType.getPredicateID());
				}
			} else {
				/* Forcing in the rest of the input states to be empty types. */
				encoding = encoding.append(mappings.add(emptyType, workfloInputStates.get(i), WorkflowElement.MEMORY_TYPE))
						.append(" 0\n");
			}

		}
		return encoding.toString();
	}

	/**
	 * Encoding the workflow output. The provided output files have to occur as the
	 * final set of "used" data types.
	 * 
	 * @param program_outputs - input types for the program
	 * @param typeAutomaton
	 * @param solutionLength
	 * @param emptyType
	 * @param mappings
	 * @param allTypes
	 * @return String representation of the workflow output encoding.
	 */
	public String encodeOutputData(List<DataInstance> program_outputs, TypeAutomaton typeAutomaton, AtomMapping mappings) {
		StringBuilder encoding = new StringBuilder();

		List<State> workflowOutputStates = typeAutomaton.getWorkflowOutputBlock().getStates();
		for (int i = 0; i < workflowOutputStates.size(); i++) {
			if (i < program_outputs.size()) {
				List<Type> currTypes = program_outputs.get(i).getTypes();
				for (Type currType : currTypes) {
					if (this.get(currType.getPredicateID()) == null) {
						System.err.println(
								"Program input '" + currType.getPredicateID() + "' was not defined in the taxonomy.");
						return null;
					}
					encoding = encoding.append(mappings.add(currType, workflowOutputStates.get(i), WorkflowElement.USED_TYPE))
							.append(" 0\n");
					this.addAnnotatedType(currType.getPredicateID());
				}
			} else {
				/* Forcing in the rest of the input states to be empty types. */
				encoding = encoding.append(mappings.add(emptyType, workflowOutputStates.get(i), WorkflowElement.USED_TYPE))
						.append(" 0\n");
			}

		}

		return encoding.toString();
	}

}
